{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df = df.sort_values(by=['row', 'col'], ascending=[True, True]).reset_index(drop=True)\n",
    "features = [\n",
    "    'AWS2', 'CAPE', 'V850', 'EWSS', 'KX', 'U250', 'U850', 'CIN', 'V250', 'R250',\n",
    "    'hour_sin','hour_cos','doy_sin','doy_cos'\n",
    "]\n",
    "target = 'AWS'\n",
    "\n",
    "df['AWS2'] = df['AWS']\n",
    "\n",
    "df['year'] = df['datetime'].dt.year\n",
    "df['hour']     = df['datetime'].dt.hour\n",
    "df['doy']      = df['datetime'].dt.dayofyear\n",
    "df['hour_sin'] = np.sin(2*np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2*np.pi * df['hour'] / 24)\n",
    "df['doy_sin']  = np.sin(2*np.pi * df['doy']  / 365)\n",
    "df['doy_cos']  = np.cos(2*np.pi * df['doy']  / 365)\n",
    "\n",
    "\n",
    "df2019 = df[df['datetime'].dt.year==2019].reset_index(drop=True)\n",
    "df2020 = df[df['datetime'].dt.year==2020].reset_index(drop=True)\n",
    "print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_f = StandardScaler()\n",
    "df2019[features] = scaler_f.fit_transform(df2019[features])\n",
    "df2020[features] = scaler_f.transform(df2020[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(data, feats, tgt, window_size, horizon):\n",
    "    X, y = [], []\n",
    "    arr_f = data[feats].values\n",
    "    arr_t = data[tgt].values\n",
    "    for i in range(window_size, len(data)-horizon+1):\n",
    "        check = False\n",
    "        for j in range(i-window_size+1, i+horizon):\n",
    "            if data['datetime'][j] - data['datetime'][j-1] != timedelta(hours=1):\n",
    "                # print(\"Datetime gap detected at index:\", j, \"between\", data['datetime'][j-1], \"and\", data['datetime'][j])\n",
    "                check = True\n",
    "                break\n",
    "        if check:\n",
    "            continue\n",
    "        X.append(arr_f[i-window_size:i])\n",
    "        y.append(arr_t[i:i+horizon])\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo X_train, y_train từ toàn bộ 2019\n",
    "window_size = 1\n",
    "horizon     = 6\n",
    "\n",
    "X_train, y_train = make_sequences(df2019, features, target, window_size, horizon)\n",
    "X_test, y_test = make_sequences(df2020, features, target, window_size, horizon)\n",
    "print(\"Train shapes:\", X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_model.fit(X_train.reshape(-1,14), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgbr_model.predict(X_test.reshape(-1,14))\n",
    "load_model = xgbr_model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "print(\"Mean Absolute Percentage Error:\", mae)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "lstm_scores, xgb_scores = [], []\n",
    "\n",
    "for tr, vl in tscv.split(X_train):\n",
    "    X_tr, X_vl = X_train[tr], X_train[vl]\n",
    "    y_tr, y_vl = y_train[tr], y_train[vl]\n",
    "    \n",
    "    # --- LSTM với EarlyStopping ---\n",
    "    model_l = Sequential([\n",
    "        LSTM(50, input_shape=(window_size,len(features))),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    model_l.compile('adam','mse')\n",
    "    es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "    model_l.fit(X_tr, y_tr, epochs=50, callbacks=[es], verbose=0)\n",
    "    p_l = model_l.predict(X_vl)\n",
    "    lstm_scores.append(np.sqrt(mean_squared_error(y_vl, p_l)))\n",
    "    \n",
    "    # --- XGBoost ---\n",
    "    X_tr_f = X_tr.reshape(len(X_tr), -1)\n",
    "    X_vl_f = X_vl.reshape(len(X_vl), -1)\n",
    "    model_x = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1\n",
    "    )\n",
    "    model_x.fit(X_tr_f, y_tr, verbose=False)\n",
    "    p_x = model_x.predict(X_vl_f)\n",
    "    xgb_scores.append(np.sqrt(mean_squared_error(y_vl, p_x)))\n",
    "\n",
    "l_rmse = np.mean(lstm_scores)\n",
    "x_rmse = np.mean(xgb_scores)\n",
    "w_l = 1/l_rmse\n",
    "w_x = 1/x_rmse\n",
    "\n",
    "print(f\"LSTM CV RMSE:   {l_rmse:.4f}\")\n",
    "print(f\"XGB   CV RMSE:   {x_rmse:.4f}\")\n",
    "print(f\"Ensemble weights → LSTM: {w_l:.2f}, XGB: {w_x:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — LSTM final —\n",
    "lstm_final = Sequential([\n",
    "    LSTM(50, input_shape=(window_size,len(features))),\n",
    "    Dense(horizon)\n",
    "])\n",
    "lstm_final.compile('adam','mse')\n",
    "es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "lstm_final.fit(X_train, y_train, epochs=50, callbacks=[es], verbose=1)\n",
    "\n",
    "# — XGBoost final —\n",
    "Xf = X_train.reshape(len(X_train), -1)\n",
    "xgb_final = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror', n_estimators=100, max_depth=5, learning_rate=0.1\n",
    ")\n",
    "xgb_final.fit(Xf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Ensemble:\n",
    "    def __init__(self, lstm_model, xgb_model, w_l, w_x):\n",
    "        self.lstm = lstm_model\n",
    "        self.xgb  = xgb_model\n",
    "        self.w_l  = w_l\n",
    "        self.w_x  = w_x\n",
    "\n",
    "    def predict(self, X):\n",
    "        y1 = self.lstm.predict(X)\n",
    "        flat = X.reshape(len(X), -1)\n",
    "        y2 = self.xgb.predict(flat).reshape(y1.shape)\n",
    "        return (self.w_l * y1 + self.w_x * y2) / (self.w_l + self.w_x)\n",
    "\n",
    "ensemble = Ensemble(lstm_final, xgb_final, w_l, w_x)\n",
    "\n",
    "with open('ensemble_final_2.pkl', 'wb') as f:\n",
    "    pickle.dump(ensemble, f)\n",
    "\n",
    "print(\"Saved ensemble model to 'ensemble_final.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "ens = pickle.load(open('ensemble_final_2.pkl','rb'))\n",
    "X_test, y_test = make_sequences(df2020, features, target, window_size, horizon)\n",
    "y_pred = ens.predict(X_test)\n",
    "print('MSE', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_day   = pd.to_datetime('2020-04-15 00:00')\n",
    "prev_times = [test_day - timedelta(hours=i) for i in range(window_size,0,-1)]\n",
    "\n",
    "\n",
    "grid = df2020[ coord_cols ].drop_duplicates().reset_index(drop=True)\n",
    "nP   = len(grid)\n",
    "\n",
    "pred_map = np.full((horizon, nP), np.nan)\n",
    "act_map  = np.full((horizon, nP), np.nan)\n",
    "\n",
    "for idx, pt in grid.iterrows():\n",
    "    # lấy subset cho điểm đó\n",
    "    cond = True\n",
    "    for c in coord_cols:\n",
    "        cond &= (df2020[c] == pt[c])\n",
    "    df_loc = df2020[cond].sort_values('datetime').reset_index(drop=True)\n",
    "    \n",
    "    # window 3h input\n",
    "    df_win = df_loc[df_loc['datetime'].isin(prev_times)]\n",
    "    if len(df_win) != window_size:\n",
    "        continue\n",
    "    \n",
    "    Xd = df_win[features].values.reshape(1, window_size, len(features))\n",
    "    y_l = lstm_final.predict(Xd).flatten()\n",
    "    y_x = xgb_final.predict(Xd.reshape(1,-1)).flatten()\n",
    "    # ensemble trọng số\n",
    "    y_e = (w_l*y_l + w_x*y_x) / (w_l + w_x)\n",
    "    pred_map[:, idx] = y_e\n",
    "    \n",
    "    # actual 6h\n",
    "    df_act = df_loc[\n",
    "        (df_loc['datetime'] >= test_day) &\n",
    "        (df_loc['datetime'] <  test_day + timedelta(hours=horizon))\n",
    "    ].sort_values('datetime')\n",
    "    if len(df_act) != horizon:\n",
    "        continue\n",
    "    act_map[:, idx] = df_act[target].values\n",
    "\n",
    "print(f\"Built maps for {nP} points.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "vmin = np.nanmin(act_map)\n",
    "vmax = np.nanmax(act_map)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=horizon, ncols=2, figsize=(10, 4*horizon))\n",
    "for h in range(horizon):\n",
    "    ax1, ax2 = axes[h]\n",
    "    ax1.scatter(grid[coord_cols[1]], grid[coord_cols[0]],\n",
    "                c=act_map[h], cmap='viridis', vmin=vmin, vmax=vmax, s=20)\n",
    "    ax1.set_title(f'Actual map in {h+1}h')\n",
    "    ax2.scatter(grid[coord_cols[1]], grid[coord_cols[0]],\n",
    "                c=pred_map[h], cmap='viridis', vmin=vmin, vmax=vmax, s=20)\n",
    "    ax2.set_title(f'Predicted map in {h+1}h')\n",
    "    xmn, xmx = grid[coord_cols[1]].min(), grid[coord_cols[1]].max()\n",
    "    ymn, ymx = grid[coord_cols[0]].min(), grid[coord_cols[0]].max()\n",
    "    ax1.set_xlim(xmn-0.5, xmx+0.5);  ax1.set_ylim(ymn-0.5, ymx+0.5)\n",
    "    ax2.set_xlim(xmn-0.5, xmx+0.5);  ax2.set_ylim(ymn-0.5, ymx+0.5)\n",
    "\n",
    "fig.colorbar(axes[0,0].collections[0], ax=axes, orientation='vertical', fraction=0.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Metrics & line chart Mean Actual vs Mean Predicted\n",
    "mask = ~np.isnan(act_map) & ~np.isnan(pred_map)\n",
    "all_act = act_map[mask]\n",
    "all_prd = pred_map[mask]\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(all_act, all_prd))\n",
    "mae  = mean_absolute_error(all_act, all_prd)\n",
    "r2   = r2_score(all_act, all_prd)\n",
    "print(f\"Test Day {test_day.date()} → RMSE={rmse:.3f}, MAE={mae:.3f}, R²={r2:.3f}\")\n",
    "\n",
    "mean_act = np.nanmean(act_map, axis=1)\n",
    "mean_prd = np.nanmean(pred_map, axis=1)\n",
    "hours = np.arange(1, horizon+1)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(hours, mean_act, marker='o', label='Mean Actual')\n",
    "plt.plot(hours, mean_prd, marker='x', label='Mean Predicted')\n",
    "plt.xlabel('Hour ahead')\n",
    "plt.ylabel('AWS')\n",
    "plt.title('Mean Actual vs Mean Predicted across grid')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
